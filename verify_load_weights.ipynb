{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595684861254",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained weights to T2I Text_Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Load filenames from: data/bird//filenames/train/filenames.pickle (8855)\nLoad filenames from: data/bird//filenames/val/filenames.pickle (2933)\nLoad from:  data/bird/captions.pickle\nn_word :  5450\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from data_loader import Text_Dataset\n",
    "from text_encoder import Text_Encoder as LM\n",
    "import trainer\n",
    "\n",
    "# Text Dataset to get the number of whole words\n",
    "hr_dataset = Text_Dataset(data_dir='data/bird/',\n",
    "                            split='train',\n",
    "                            words_num=15,\n",
    "                            print_shape=False)\n",
    "                            \n",
    "# hyper parameters same to T2I code\n",
    "n_word = hr_dataset.n_word\n",
    "print('n_word : ', n_word)\n",
    "embedding_dim = 1024\n",
    "hidden_size = 1024\n",
    "n_layers = 1\n",
    "dropout = .5\n",
    "max_length = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T2I's Text_Encoder Class\n",
    "class Text_Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, rnn_type):\n",
    "        super(Text_Encoder, self).__init__()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.vocap_size = vocab_size\n",
    "        self.embedding_dim = 1024 #embedding size\n",
    "        self.drop_rate = 0.5 #dropout rate\n",
    "        self.hidden_dim = 1024 # word dim\n",
    "        self.num_layers = 1\n",
    "        self.bidirectional = True # bidirectional option\n",
    "\n",
    "        if self.bidirectional:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "\n",
    "        self.hidden_dim = self.hidden_dim // self.num_directions\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=self.vocap_size, embedding_dim=self.embedding_dim)\n",
    "        self.dropout = nn.Dropout(self.drop_rate)\n",
    "\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(input_size = self.embedding_dim,\n",
    "                               hidden_size=self.hidden_dim,\n",
    "                               num_layers=self.num_layers,\n",
    "                               batch_first=True,\n",
    "                               dropout=self.drop_rate,\n",
    "                               bidirectional=self.bidirectional)\n",
    "        else:\n",
    "            self.rnn = nn.GRU(input_size = self.embedding_dim,\n",
    "                              hidden_size=self.hidden_dim,\n",
    "                              num_layers=self.num_layers,\n",
    "                              batch_first=True,\n",
    "                              dropout=self.drop_rate,\n",
    "                              bidirectional=self.bidirectional)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            return (weight.new(self.num_layers * self.num_directions, batch_size, self.hidden_dim).zero_(),\n",
    "                    weight.new(self.num_layers * self.num_directions, batch_size, self.hidden_dim).zero_())\n",
    "        else:\n",
    "            return weight.new(self.num_layers * self.num_directions, batch_size, self.hidden_dim).zero_()\n",
    "\n",
    "    def forward(self, captions, cap_lens, hidden, mask=None):\n",
    "        embed = self.embedding_layer(captions)\n",
    "        embed = self.dropout(embed)\n",
    "\n",
    "        cap_lens = cap_lens.data.tolist()\n",
    "        embed = pack_padded_sequence(embed, cap_lens, batch_first=True)\n",
    "\n",
    "        out, hidden = self.rnn(embed, hidden)\n",
    "        out = pad_packed_sequence(out, batch_first=True)[0]\n",
    "        words_emb = out.transpose(1, 2)\n",
    "\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            sentence_emb = hidden[0].transpose(0, 1).contiguous()\n",
    "        else:\n",
    "            sentence_emb = hidden.transpose(0, 1).contiguous()\n",
    "        sentence_emb = sentence_emb.view(-1, self.hidden_dim * self.num_directions)\n",
    "\n",
    "        return words_emb, sentence_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Text_Encoder(vocab_size=5450, rnn_type='LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = torch.load('basic.14.0.06-1.06.0.15-1.16.pt')['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OrderedDict([('embedding_layer.weight',\n              tensor([[ 2.2491e-01,  1.2387e+00, -1.6484e+00,  ..., -1.8124e-01,\n                        8.2356e-01, -5.2841e-01],\n                      [ 6.9791e-02,  6.4899e-03,  6.0361e-01,  ...,  1.0983e+00,\n                        1.2417e+00,  9.0354e-04],\n                      [ 1.1542e+00,  1.7226e-02,  3.0986e-01,  ..., -5.2637e-01,\n                        9.2248e-01, -5.5523e-01],\n                      ...,\n                      [ 2.7472e-01, -1.7736e+00, -8.7598e-01,  ...,  1.5634e+00,\n                       -2.0526e+00,  7.4461e-01],\n                      [-9.0740e-01, -2.1600e+00, -5.4583e-01,  ..., -1.7708e+00,\n                        1.0711e+00,  4.1583e-01],\n                      [ 2.8366e-01, -2.9290e-02, -8.6192e-01,  ...,  9.7635e-01,\n                       -1.4004e+00, -7.4893e-01]], device='cuda:0')),\n             ('out.weight',\n              tensor([[ 0.0157,  0.0038, -0.0051,  ...,  0.0176, -0.0093,  0.0066],\n                      [ 0.1018, -0.1262,  0.1556,  ...,  0.0039, -0.2740,  0.1521],\n                      [-0.0585, -0.0548, -0.1775,  ..., -0.1596, -0.1192, -0.2361],\n                      ...,\n                      [ 0.0105, -0.0306, -0.0134,  ...,  0.0042,  0.0171,  0.0022],\n                      [ 0.0073,  0.0127,  0.0268,  ..., -0.0014, -0.0349, -0.0212],\n                      [ 0.0326,  0.0173, -0.0054,  ...,  0.0051,  0.0039, -0.0082]],\n                     device='cuda:0')),\n             ('out.bias',\n              tensor([-0.0549,  1.5555,  0.9475,  ..., -0.0634, -0.1012, -0.0698],\n                     device='cuda:0')),\n             ('rnn.weight_ih_l0',\n              tensor([[ 2.1626e-03,  3.6644e-03,  4.9683e-02,  ..., -6.0552e-02,\n                        1.2779e-01,  3.3292e-02],\n                      [-3.3347e-02,  5.6622e-02, -4.4625e-02,  ...,  1.2050e-02,\n                       -4.6819e-02,  4.2776e-02],\n                      [ 1.1162e-01, -3.7768e-02,  9.1224e-02,  ..., -1.1963e-01,\n                        2.2207e-01,  2.0064e-02],\n                      ...,\n                      [ 4.2706e-02, -4.0159e-02,  4.6796e-03,  ..., -1.0592e-02,\n                        4.0791e-02,  2.4128e-02],\n                      [-2.5209e-02, -3.9101e-02,  4.1032e-02,  ...,  8.2529e-02,\n                        5.5519e-02,  1.1991e-01],\n                      [-3.4552e-03,  8.3318e-02, -1.2861e-04,  ..., -3.2717e-03,\n                        1.6193e-02,  3.7680e-02]], device='cuda:0')),\n             ('rnn.weight_hh_l0',\n              tensor([[-0.0468, -0.0104,  0.0321,  ...,  0.0118, -0.0420,  0.0066],\n                      [-0.0175, -0.0450, -0.0456,  ..., -0.0039,  0.0095, -0.0544],\n                      [ 0.0013, -0.0379, -0.0280,  ..., -0.0209,  0.0052, -0.0362],\n                      ...,\n                      [-0.0170, -0.0225, -0.0232,  ...,  0.0204, -0.0219, -0.0042],\n                      [-0.0407,  0.0489, -0.0480,  ...,  0.0202,  0.0142,  0.0178],\n                      [-0.0352,  0.0082, -0.0716,  ...,  0.0564,  0.0211,  0.0141]],\n                     device='cuda:0')),\n             ('rnn.bias_ih_l0',\n              tensor([ 0.0741, -0.0225, -0.0181,  ...,  0.0935,  0.0761, -0.0108],\n                     device='cuda:0')),\n             ('rnn.bias_hh_l0',\n              tensor([ 0.0185, -0.0569,  0.0117,  ...,  0.0295,  0.1115,  0.0464],\n                     device='cuda:0')),\n             ('rnn.weight_ih_l0_reverse',\n              tensor([[-0.0577, -0.0788, -0.0689,  ..., -0.1572, -0.0963, -0.0621],\n                      [ 0.1746, -0.0195,  0.0367,  ...,  0.0287, -0.0469, -0.0082],\n                      [ 0.0074,  0.1249,  0.0362,  ...,  0.0210, -0.0265, -0.0497],\n                      ...,\n                      [-0.0188,  0.0929,  0.0464,  ...,  0.0216,  0.0403, -0.1037],\n                      [ 0.0236, -0.0443,  0.1508,  ...,  0.0015,  0.0093,  0.0445],\n                      [ 0.0015,  0.0239,  0.1496,  ...,  0.1791, -0.0226,  0.0534]],\n                     device='cuda:0')),\n             ('rnn.weight_hh_l0_reverse',\n              tensor([[ 0.0955, -0.1028, -0.0335,  ..., -0.1023,  0.0533,  0.0868],\n                      [ 0.0583, -0.0513, -0.0286,  ...,  0.0214,  0.0027,  0.0835],\n                      [-0.0082, -0.0621, -0.0390,  ..., -0.0453,  0.0382,  0.0251],\n                      ...,\n                      [-0.0173, -0.0106,  0.0362,  ...,  0.0614,  0.0687, -0.0343],\n                      [-0.1221,  0.1129,  0.0859,  ...,  0.0483, -0.0210, -0.0772],\n                      [ 0.0552,  0.0029, -0.0101,  ..., -0.0582,  0.0152, -0.0703]],\n                     device='cuda:0')),\n             ('rnn.bias_ih_l0_reverse',\n              tensor([0.3588, 0.3080, 0.0988,  ..., 0.1060, 0.1061, 0.1715], device='cuda:0')),\n             ('rnn.bias_hh_l0_reverse',\n              tensor([0.3682, 0.2688, 0.1538,  ..., 0.1519, 0.0705, 0.1843], device='cuda:0'))])"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "_IncompatibleKeys(missing_keys=[], unexpected_keys=['out.weight', 'out.bias'])"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "model.load_state_dict(load_model, strict=False)"
   ]
  }
 ]
}